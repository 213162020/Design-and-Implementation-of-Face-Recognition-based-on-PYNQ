{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入NCS—SK—API\n",
    "from mvnc import mvncapi as mvnc\n",
    "# 导入facenet模块包\n",
    "import facenet_ncs_FPGA\n",
    "import cv2\n",
    "import pynq.pynq_computervision.overlays.computer_vision.xf_resize_accel as xv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "from time import sleep\n",
    "import realtime_input\n",
    "\n",
    "# 加载.bit文件\n",
    "base = BaseOverlay(\"base.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "# 设置摄像头输入分辨率\n",
    "frame_in_w = 640\n",
    "frame_in_h = 480\n",
    "# 打开摄像头\n",
    "# Configure webcam - note that output images will be BGR\n",
    "#videoIn = cv2.VideoCapture('/home/xilinx/jupyter_notebooks/ncs-facenet_tensorflow/images/2.jpg')\n",
    "#videoIn = cv2.VideoCapture('C:\\\\Users\\\\Administrator\\\\face_detect\\\\face_detect.mp4')\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x29de1290>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置HDMI视频输出\n",
    "hdmi_out = base.video.hdmi_out\n",
    "\n",
    "# 输出分辨率、通道顺序（与输入一致）\n",
    "mode = VideoMode(frame_in_w,frame_in_h,24)\n",
    "hdmi_out.configure(mode, PIXEL_BGR)\n",
    "\n",
    "# 开启HDMI输出\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ！！！facenet模型文件路径 ——— facenet.graph ！！！\n",
    "GRAPH_FILENAME = \"/home/xilinx/jupyter_notebooks/ncs-facenet_tensorflow/models/facenet.graph\"\n",
    "# 人脸录入路径\n",
    "targets_list_dir = '/home/xilinx/jupyter_notebooks/ncs-facenet_tensorflow/targets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!ok ok ok!!!\n"
     ]
    }
   ],
   "source": [
    "# 检查NCS\n",
    "devices = mvnc.EnumerateDevices()\n",
    "if len(devices) == 0:\n",
    "    print('No NCS devices found')\n",
    "    quit()\n",
    "# 开启NCS\n",
    "device = mvnc.Device(devices[0])\n",
    "device.OpenDevice()\n",
    "# 准备模型文件(加载至片上内存)——facenet.graph\n",
    "graph_file_name = GRAPH_FILENAME\n",
    "with open(graph_file_name, mode='rb') as f:\n",
    "    graph_in_memory = f.read()\n",
    "graph = device.AllocateGraph(graph_in_memory)\n",
    "# 获取人脸目标路径\n",
    "temp_list = {}\n",
    "targets_list = os.listdir(targets_list_dir)\n",
    "targets_list = [i for i in targets_list if i.endswith('.jpg')]\n",
    "# ！！！人脸录入 ！！！（获取目标人脸特征集）\n",
    "targets_feature = facenet_ncs_FPGA.feature(targets_list, temp_list, graph)\n",
    "print('!!!ok ok ok!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = BareHDMIOverlay('/home/xilinx/jupyter_notebooks/CV/pynq_computervision/overlays/computer_vision/resize.bit')\n",
    "\n",
    "    \n",
    "# 实时循环识别人脸\n",
    "Delay = 0.5\n",
    "i = 0\n",
    "while True:\n",
    "    # 读入一帧图像\n",
    "    ret, frame1 = videoIn.read()\n",
    "    #cv2.rectangle(frame, (0+offset, 0+offset),(input_frame.shape[1]-offset-1, input_frame.shape[0]-offset-1),rectangle_color, 10)\n",
    "    cv2.rectangle(frame1, (200, 80),(440, 400),(0,255,0), 3)\n",
    "    \n",
    "    if (base.buttons[0].read()==1):\n",
    "        sleep(Delay)\n",
    "        if (base.buttons[0].read()==1):\n",
    "            for led in base.leds:\n",
    "                led.toggle()\n",
    "            targets_feature, targets_list = realtime_input.realtime_input(frame1, hdmi_out, graph, videoIn)\n",
    "   \n",
    "    i = i + 1\n",
    "    # 每隔2帧处理1帧图像\n",
    "    if(i > 2):\n",
    "        i = 0\n",
    "        # ！！！人脸识别 ！！！\n",
    "        frame2 = frame1[80:400, 200:440]\n",
    "        frame_res = facenet_ncs_FPGA.run_images(targets_feature, targets_list, graph, frame1, frame2)   \n",
    "        \n",
    "        # !!!FPGA—resize!!!\n",
    "        xv2.resize(inframe, dst=outframe)# 输出结果大小调整\n",
    "        \n",
    "        frame_out = hdmi_out.newframe()\n",
    "          # ！图像由ARM——>FPGA！\n",
    "        frame_out[:,:,:] = outframe[:,:,:]\n",
    "        hdmi_out.writeframe(frame_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
